# GlobeMarketMind - Global Market Sentiment Analysis

This is a Flask-based system that analyzes the mood/sentiment of **79 global stock markets** across 6 continents. It automatically calculates a "mood index" for each market and shows how different markets are correlated with each other.

## Architecture Overview

```
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚                         CLIENT LAYER                                      â”‚
â”‚  â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”  â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”  â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”      â”‚
â”‚  â”‚  Web Browser     â”‚  â”‚  API Client      â”‚  â”‚  3D Visualization â”‚      â”‚
â”‚  â”‚  (Swagger UI)    â”‚  â”‚  (curl/Postman)  â”‚  â”‚  (Three.js)       â”‚      â”‚
â”‚  â””â”€â”€â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜  â””â”€â”€â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜  â””â”€â”€â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜      â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
            â”‚                    â”‚                    â”‚
            â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
                                 â†“
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚                    API GATEWAY (Nginx:80)                                 â”‚
â”‚         Routes /api/* â†’ Backend | /apidocs â†’ Swagger UI                  â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
                                 â†“
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚                   BACKEND SERVICE (Flask:5000)                            â”‚
â”‚                                                                           â”‚
â”‚  â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â” â”‚
â”‚  â”‚  LAYER 1: Process Orchestration (process_bp.py)                    â”‚ â”‚
â”‚  â”‚  â€¢ Pipeline coordination                                            â”‚ â”‚
â”‚  â”‚  â€¢ Manual/scheduled triggers                                        â”‚ â”‚
â”‚  â”‚  â€¢ Snapshot generation                                              â”‚ â”‚
â”‚  â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜ â”‚
â”‚                              â†“                                            â”‚
â”‚  â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â” â”‚
â”‚  â”‚  LAYER 2: Business Logic (analytics.py)                            â”‚ â”‚
â”‚  â”‚  â€¢ FeatureCalculator: Volatility, Returns, Volume Ratios          â”‚ â”‚
â”‚  â”‚  â€¢ MoodEngine: Mood Index = 0.5Ã—Return - 0.3Ã—Vol + 0.2Ã—Volume    â”‚ â”‚
â”‚  â”‚  â€¢ CorrelationCalculator: Pearson correlation between markets     â”‚ â”‚
â”‚  â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜ â”‚
â”‚                              â†“                                            â”‚
â”‚  â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â” â”‚
â”‚  â”‚  LAYER 3: Data Adapter (adapter.py)                                â”‚ â”‚
â”‚  â”‚  â€¢ Yahoo Finance API integration                                   â”‚ â”‚
â”‚  â”‚  â€¢ 79 market symbols mapping (US_SPX â†’ ^GSPC)                     â”‚ â”‚
â”‚  â”‚  â€¢ Mock data fallback for testing                                  â”‚ â”‚
â”‚  â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜ â”‚
â”‚                              â†“                                            â”‚
â”‚  â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â” â”‚
â”‚  â”‚  LAYER 4: Data Persistence (data_service.py)                       â”‚ â”‚
â”‚  â”‚  â€¢ Save daily_state (mood_index, volatility, trend)               â”‚ â”‚
â”‚  â”‚  â€¢ Save correlation_edges (market relationships)                   â”‚ â”‚
â”‚  â”‚  â€¢ Query historical data                                            â”‚ â”‚
â”‚  â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜ â”‚
â”‚                              â†“                                            â”‚
â”‚  â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â” â”‚
â”‚  â”‚  SCHEDULER (scheduler.py)                                           â”‚ â”‚
â”‚  â”‚  â€¢ Daily Analysis: 9:00 AM UTC (auto-fetch + analyze)             â”‚ â”‚
â”‚  â”‚  â€¢ Weekly Cleanup: Sunday 2:00 AM (delete old data)               â”‚ â”‚
â”‚  â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜ â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
                                 â†“
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚                   DATABASE (PostgreSQL:5432)                              â”‚
â”‚                                                                           â”‚
â”‚  â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”  â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”  â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”â”‚
â”‚  â”‚  market_registry     â”‚  â”‚  daily_state         â”‚  â”‚ correlation_   â”‚â”‚
â”‚  â”‚  â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€   â”‚  â”‚  â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€   â”‚  â”‚ edges          â”‚â”‚
â”‚  â”‚  â€¢ id (PK)           â”‚â†â”€â”‚  â€¢ market_id (FK)    â”‚  â”‚ â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€     â”‚â”‚
â”‚  â”‚  â€¢ name              â”‚  â”‚  â€¢ date              â”‚  â”‚ â€¢ source_id(FK)â”‚â”‚
â”‚  â”‚  â€¢ latitude          â”‚  â”‚  â€¢ mood_index        â”‚  â”‚ â€¢ target_id(FK)â”‚â”‚
â”‚  â”‚  â€¢ longitude         â”‚  â”‚  â€¢ volatility_30d    â”‚  â”‚ â€¢ correlation_ â”‚â”‚
â”‚  â”‚  â€¢ market_group      â”‚  â”‚  â€¢ trend_strength    â”‚  â”‚   value        â”‚â”‚
â”‚  â”‚  â€¢ country           â”‚  â”‚  â€¢ updated_at        â”‚  â”‚ â€¢ date         â”‚â”‚
â”‚  â”‚                      â”‚  â”‚                      â”‚  â”‚ â€¢ updated_at   â”‚â”‚
â”‚  â”‚  79 markets          â”‚  â”‚  Time-series data    â”‚  â”‚ Graph data     â”‚â”‚
â”‚  â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜  â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜  â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜

                                 â†“
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚               EXTERNAL DATA SOURCE (Yahoo Finance API)                    â”‚
â”‚  â€¢ Real-time stock prices (OHLCV data)                                   â”‚
â”‚  â€¢ 30-day historical data for volatility calculation                     â”‚
â”‚  â€¢ 79 global market indices                                              â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
```

### Data Flow Example

When you trigger an analysis (`POST /api/process/analyze`):

1. **Process Layer** â†’ Receives request, starts pipeline
2. **Adapter Layer** â†’ Fetches data from Yahoo Finance (79 markets)
3. **Analytics Layer** â†’ Calculates mood indexes, volatilities, correlations
4. **Data Service Layer** â†’ Saves 79 daily_state records + correlation_edges
5. **Database** â†’ Stores results with timestamps
6. **API Response** â†’ Returns summary to client

## Quick Start

### 1. Start the Project

```bash
docker compose up -d
```

Wait a bit until the database is healthy:
```
marketmind-postgres: ... healthy
```

Then you can query the data:
```bash
curl http://localhost/api/data/markets
```

If you have `jq` installed, you can format it nicely:
```bash
curl http://localhost/api/data/markets | jq
```

### 2. Check the API Docs

Open in browser: `http://localhost/apidocs`

You'll see all the endpoints and can test them directly in the browser.

## Markets We Track

We now track **79 global stock market indices** across 6 continents:

- ğŸŒ **North America** (10): S&P 500, Dow Jones, Nasdaq, Russell 2000, TSX, IPC Mexico, etc.
- ğŸŒ **Europe** (26): FTSE 100, DAX, CAC 40, FTSE MIB, IBEX 35, SMI, STOXX 50, etc.
- ğŸŒ **Asia-Pacific** (25): Nikkei 225, Shanghai Composite, Hang Seng, KOSPI, TAIEX, Sensex, ASX 200, etc.
- ğŸŒ **Latin America** (8): Bovespa, Merval, IPSA Chile, COLCAP Colombia, etc.
- ğŸŒ **Middle East** (6): Tel Aviv 125, TASI Saudi Arabia, ADX/DFM UAE, etc.
- ğŸŒ **Africa** (4): JSE South Africa, EGX Egypt, MASI Morocco

**Market Classification**:
- **DM (Developed Markets)**: 42 markets (US, Europe, Japan, Australia, etc.)
- **EM (Emerging Markets)**: 37 markets (China, India, Brazil, Russia, etc.)

Total: **79 markets**.

## API Endpoints
Details is in the API docs,swagger, but here are the main ones:
```
GET  /api/data/markets                          Get all markets
GET  /api/data/markets/US_SPX                   Get one market
GET  /api/history/markets/US_SPX/timeseries     Get historical data (?days=10)
POST /api/history/compare                       Compare two markets
GET  /api/history/rankings                      Rankings (?metric=mood_index)
GET  /api/process/snapshot                      Current snapshot
POST /api/process/analyze                       Manually trigger analysis
```

## How We Calculate Stuff

**Mood Index** (ranges from -1 to +1):
- Stock goes up a lot â†’ mood is good
- High volatility â†’ mood is bad
- High trading volume â†’ mood is good

Formula: `0.5 Ã— daily_return - 0.3 Ã— volatility + 0.2 Ã— volume_score`

**Volatility**: Measured over 30 days

**Correlation**: Shows how markets move together (e.g., when Asia goes up, Europe usually goes up too)

## Automation

Runs at 9 AM UTC every day to fetch new data, and cleans up old data once a week.

## Testing

### Run End-to-End Test

This checks if the whole pipeline works (fetch data â†’ analyze â†’ save):

```bash
cd backend
python tests/test_e2e_pipeline.py
```

Output looks like:
```
âœ“ All 15 markets fetched successfully
âœ“ Analysis completed, found N correlations
âœ“ Data saved successfully
```

### Run Integration Tests

Tests all the API endpoints to make sure they work:

```bash
cd backend
python tests/test_integration.py
```

### Run Performance Tests

See how fast the API is and how much it can handle:

```bash
cd backend
python tests/test_performance.py
```

### Run Unit Tests

Test individual modules:

```bash
cd backend
python tests/test_adapter.py      # Data adapter
python tests/test_analytics.py    # Analysis algorithms
```

## Project Structure

```
backend/
â”œâ”€â”€ app/                      # Main code
â”‚   â”œâ”€â”€ api/                  # API routes
â”‚   â”œâ”€â”€ services/             # Business logic
â”‚   â””â”€â”€ models/               # Database models
â”œâ”€â”€ tests/                    # Test code
â”‚   â”œâ”€â”€ test_e2e_pipeline.py
â”‚   â”œâ”€â”€ test_integration.py
â”‚   â””â”€â”€ other tests...
â””â”€â”€ requirements.txt          # Dependencies

docker/
â”œâ”€â”€ Dockerfile.backend        # Container config
â”œâ”€â”€ nginx.conf               # Gateway config
â””â”€â”€ init.sql                 # Database setup
```

## Stop the Project

```bash
# Stop containers
docker compose down

# Stop and delete database data (start fresh)
docker compose down -v
```

## Requirements

- Docker & Docker Compose
- Internet connection (to fetch Yahoo Finance data)

## Development

```bash
# Start only the database
docker compose up postgres -d

# Run backend locally
cd backend
python -m flask run

# Auto-reload on code changes (need python-dotenv)
FLASK_ENV=development python -m flask run
```
